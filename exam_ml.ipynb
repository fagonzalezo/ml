{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam\n",
    "# Machine Learning 2015-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After solving all the questions in the exam save your notebook with the name `username.ipynb` and submit it to: https://www.dropbox.com/request/KN8GwdAIi0Hl2jk2mg2E\n",
    "\n",
    "---\n",
    "\n",
    "The following code implements a simple one-neuron neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def predict(w, x):\n",
    "    x = np.append(np.array([1]), x)\n",
    "    return sigmoid(np.dot(w, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (1.0)\n",
    "Find a weight vector such that the neural network calculates the NOR function:\n",
    "    \n",
    "$$f(x,y)=\\neg(x\\vee y)$$\n",
    "\n",
    "Use the following function to test your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Prediction error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9a91307e9c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtest_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-9a91307e9c36>\u001b[0m in \u001b[0;36mtest_prediction\u001b[0;34m(X, Y, w)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Prediction error"
     ]
    }
   ],
   "source": [
    "def test_prediction(X, Y, w):\n",
    "    epsilon = 0.001\n",
    "    for i, x in enumerate(X):\n",
    "        if np.abs(predict(w, x) - Y[i]) > epsilon:\n",
    "            raise Exception(\"Prediction error\")\n",
    "    return True\n",
    "\n",
    "X = [[0, 0],\n",
    " [0, 1],\n",
    " [1, 0],\n",
    " [1, 1]]\n",
    "Y = [1, 0, 0 ,0]\n",
    "w = np.array([0, 0, 0])\n",
    "test_prediction(X, Y, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (1.0)\n",
    "\n",
    "The following function calculates the loss function of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    return (predict(w, x) - y) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that calculates the gradient of the loss with respect to the weights:\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial w} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def de_dw(w, x, y):\n",
    "    delta = np.zeros(len(w))\n",
    "    # put your code here\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following functions to test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "de_dw test failed!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f9f100f98c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"de_dw test failed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtest_de_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-f9f100f98c0c>\u001b[0m in \u001b[0;36mtest_de_dw\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnum_de_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"de_dw test failed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtest_de_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: de_dw test failed!"
     ]
    }
   ],
   "source": [
    "def num_de_dw(w, x, y, epsilon):\n",
    "    deltas = np.identity(len(w)) * epsilon\n",
    "    de = np.zeros(len(w))\n",
    "    for i in range(len(w)):\n",
    "        de[i] = (loss(w + deltas[i, :], x, y) - loss(w - deltas[i, :], x, y)) / (2 * epsilon)\n",
    "    return de\n",
    "\n",
    "def test_de_dw():\n",
    "    num_tests = 100\n",
    "    epsilon = 0.0001\n",
    "    for i in range(num_tests):\n",
    "        tw = np.random.randn(3)\n",
    "        tx = np.random.randn(2)\n",
    "        ty = np.random.randn(1)\n",
    "        if np.linalg.norm(de_dw(tw, tx,ty) - num_de_dw(tw, tx, ty, epsilon)) > epsilon:\n",
    "            raise Exception(\"de_dw test failed!\")\n",
    "\n",
    "test_de_dw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the gradient function to train the neural network using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(w, X, Y):\n",
    "    result = 0\n",
    "    for i, x in enumerate(X):\n",
    "        result += loss(w, x, Y[i])\n",
    "    return result\n",
    "\n",
    "def train(X, Y, epochs, eta, w_ini):\n",
    "    losses = []\n",
    "    w = w_ini\n",
    "    for i in range(epochs):\n",
    "        delta = np.zeros(len(w))\n",
    "        for i, x in enumerate(X):\n",
    "            delta += de_dw(w, x, Y[i])\n",
    "        w = w - eta * delta\n",
    "        losses.append(evaluate(w, X, Y))\n",
    "    return w, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.]\n",
      "0.5\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJDXAsJekBvwf9LUdiElWrDoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ad16850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]\n",
    "Y = [0, 0, 1, 0]\n",
    "w, losses = train(X, Y, 50, 10, [0, 0, 0])\n",
    "pl.plot(losses)\n",
    "print w\n",
    "print predict(w, [1, 0])\n",
    "print predict(w, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (1.0)\n",
    "\n",
    "Now we will modify the loss function to include a regularization term:\n",
    "$$ E(w,D)=\\frac{1}{2}\\sum_{(x_{i},y_{i})\\in D}(f(w,x_{i})-y_{i})^{2}+\\frac{\\text{1}}{2}\\beta\\left\\Vert w\\right\\Vert _{2}^{2}$$\n",
    "\n",
    "where $f(w,x_{i})$ is the prediction calculated by the neural network.\n",
    "\n",
    "To accomplish this you must modify the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_loss(w, beta, x, y):\n",
    "    loss = 0\n",
    "    # your code here\n",
    "    return loss\n",
    "\n",
    "def reg_de_dw(w, beta, x, y):\n",
    "    delta = np.zeros(len(w))\n",
    "    # put your code here\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following functions to test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reg_num_de_dw(w, beta, x, y, epsilon):\n",
    "    deltas = np.identity(len(w)) * epsilon\n",
    "    de = np.zeros(len(w))\n",
    "    for i in range(len(w)):\n",
    "        de[i] = (reg_loss(w + deltas[i, :], beta, x, y) - reg_loss(w - deltas[i, :], beta, x, y)) / (2 * epsilon)\n",
    "    return de\n",
    "\n",
    "def reg_test_de_dw():\n",
    "    num_tests = 100\n",
    "    epsilon = 0.0001\n",
    "    beta = 1\n",
    "    for i in range(num_tests):\n",
    "        tw = np.random.randn(3)\n",
    "        tx = np.random.randn(2)\n",
    "        ty = np.random.randn(1)\n",
    "        if np.linalg.norm(reg_de_dw(tw, beta, tx, ty) - reg_num_de_dw(tw, beta, tx, ty, epsilon)) > epsilon:\n",
    "            raise Exception(\"reg_de_dw test failed!\")\n",
    "\n",
    "reg_test_de_dw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (1.0)\n",
    "Now train the neural network using regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_evaluate(w, beta, X, Y):\n",
    "    result = 0\n",
    "    # your code here\n",
    "    return result\n",
    "\n",
    "def reg_train(X, Y, epochs, eta, w_ini, beta):\n",
    "    losses = []\n",
    "    w = np.array(w_ini)\n",
    "    # your code here\n",
    "    return w, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "0.5\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEH3JXNEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ac90650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]\n",
    "Y = [0, 0, 1, 0]\n",
    "wr, losses = reg_train(X, Y, 50, 2, [0, 0, 0], 0.01)\n",
    "pl.plot(losses)\n",
    "print wr\n",
    "print predict(wr, [1, 0])\n",
    "print predict(wr, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the effect of regularization? Discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (1.0)\n",
    "Here, we will build a kernel version of the previous neural network, i.e., a neural network able to work in a \n",
    "feature space induced by a kernel. To do this we will express the weight vector as a linear combination of vectors in a set $X$:\n",
    "\n",
    "$$ w=\\sum_{x_{i}\\in X}\\alpha_{i}\\phi(x_{i}) $$\n",
    "\n",
    "Now, implement this modifying the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_predict(alpha, X, kernel, x):\n",
    "    result = 0\n",
    "    # your code here\n",
    "    return sigmoid(result)\n",
    "    \n",
    "def k_loss(alpha, X, beta, kernel, x, y):\n",
    "    loss = 0\n",
    "    # your code here\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your functions with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0\n",
      "0.5 0\n",
      "0.5 0\n",
      "0.5 0\n",
      "--------\n",
      "0.5 0\n",
      "0.5 0\n",
      "0.5 0\n",
      "0.5 0\n"
     ]
    }
   ],
   "source": [
    "alpha = [1, 0.5, -0.3, -0.4]\n",
    "Xs = [[0.1, -0.5],\n",
    "     [0.5, 1.0],\n",
    "     [-1.0, 0.5],\n",
    "     [1.0, 1.0]]\n",
    "\n",
    "def k1(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def k2(x, y):\n",
    "    return (np.dot(x, y) + 1) ** 2\n",
    "\n",
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]\n",
    "Y = [0, 0, 1, 0]\n",
    "for i, x in enumerate(X):\n",
    "    print k_predict(alpha, Xs, k1, x), k_loss(alpha, Xs, 1, k1, x, Y[i])\n",
    "print \"--------\"\n",
    "for i, x in enumerate(X):\n",
    "    print k_predict(alpha, Xs, k2, x), k_loss(alpha, Xs, 1, k2, x, Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (optional, extra credit)\n",
    "\n",
    "Train the kernel neural network using gradient descent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
